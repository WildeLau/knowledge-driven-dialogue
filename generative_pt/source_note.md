Source Code Reading Note
=========================

## Entery

run_train.sh

## Code Structure

``` 
- generative_pt/
  |- data/
    # all data set that used and generated for training
     |- resource/
       # original data and sample data extracted from them
        - dev.txt
        - test.txt
        - train.txt
          # train.txt and dev.txt are session data, test.txt are session data
        - sample.dev.txt
        - sample.train.txt
          # extracted by "./tools/convert_session_to_sample.py"
     - demo.dev
     - demo.test
     - demo.train
       # text file
     - demo.dev.topic
     - demo.train.topic
       # topic file is a dict, used to keep relationship between slot and original topic
       # generated by "./tools/convert_conversation_corpus_to_model_txt.py"
       # "demo" is the name of model, is set in run_train.sh and network.py
  |- models/
    # saved model file and test result
     - best.model
  |- output/
     - test.result
      # result with solt mark
     - test.result.final
      # result with solt mark replaced
      # generated by "./tools/topic_materialization.py"
      # use topic file as input
     - test.result.eval
      # generated by "./tools/convert_result_for_eval.py"
  |- source/
  |- tools/
     - conversation_client.py
     - conversation_server.py
     - conversation_strategy.py
     - convert_conversation_corpus_to_model_text.py
      # 2nd step
      # model text: chat path + konwledge str + history + response + konwledge str again
      # replace topic with solt mark
     - convert_result_for_eval.py
     - convert_session_to_sample.py
      # 1st step
      # 1 session to n sample, sample is a dict, contain "goal", "knowledge", "history", "response"
     - eval.py
     - topic_materialization.py
      # solt mark -> topic, 输入文件和topic file依靠行号对齐
  - network.py
  - run_test.sh
    # same as run_train.sh until training
    # test from "network.py", generate test.result
    # replace slot mark
    # eval dev set result
  - run_train.sh
    # set gpu
    # whether use slot mark for topic A/B
    # set python path
    # convert data
    # training from "network.py"
```


### train_iter

object create by mathoed KnowledgeCorpus.create_batches()


### KnowledgeCorpus

calss, initialized by raw data,
vocab size: 30000
sentence min len: 1; max len: 500
no embedding file, without label
share vocab